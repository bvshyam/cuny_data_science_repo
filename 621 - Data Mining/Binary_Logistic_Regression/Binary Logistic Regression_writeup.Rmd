---
title: "Binary Logistic Regression"
author: "Shyam BV"
date: "March 15, 2018"
output:
  pdf_document: 
    number_sections: yes
    toc: yes
    toc_depth: 3
    highlight: tango
  html_document:
    fontsize: 35pt
    highlight: pygments
    theme: cerulean
    toc: yes
---


********


\newpage 

# **Binary Linear Regression Model : Predicting whether there is a crime or not**

********


Deliverables:

1. A write-up submitted in PDF format. Your write-up should have four sections. Each one is described below. You may assume you are addressing me as a fellow data scientist, so do not need to shy away from technical details.
2. Assigned predictions (the number of wins for the team) for the evaluation data set.
3. Include your R statistical programming code in an Appendix.


```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}


library(dplyr)
library(ggplot2)
library(MASS)
library(faraway)
library(PerformanceAnalytics)
library(leaps)
library(bestglm)
library(rstanarm)
library(caret)
library(pROC)
```


## Data Exploration

Describe the size and the variables in the moneyball training data set. Consider that too much detail will cause a manager to lose interest while too little detail will make the manager consider that you arenâ€™t doing your job. Some suggestions are given below. Please do NOT treat this as a check list of things to do to complete the assignment. You should have your own thoughts on what to tell the boss. These are just ideas.

a. Mean / Standard Deviation / Median
b. Bar Chart or Box Plot of the data and/or Histograms
c. Is the data correlated to the target variable (or to other variables?)
d. Are any of the variables missing and need to be imputed "fixed"?



```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
df = read.csv('./data/crime-training-data.csv')

```


Below is the definition of all the predictors in the dataset.

. zn: proportion of residential land zoned for large lots (over 25000 square feet) (predictor variable)
. indus: proportion of non-retail business acres per suburb (predictor variable)
. chas: a dummy var. for whether the suburb borders the Charles River (1) or not (0) (predictor variable)
. nox: nitrogen oxides concentration (parts per 10 million) (predictor variable)
. rm: average number of rooms per dwelling (predictor variable)
. age: proportion of owner-occupied units built prior to 1940 (predictor variable)
. dis: weighted mean of distances to five Boston employment centers (predictor variable)
. rad: index of accessibility to radial highways (predictor variable)
. tax: full-value property-tax rate per $10,000 (predictor variable)
. ptratio: pupil-teacher ratio by town (predictor variable)
. black: 1000(Bk - 0.63)2 where Bk is the proportion of blacks by town (predictor variable)
. lstat: lower status of the population (percent) (predictor variable)
. medv: median value of owner-occupied homes in $1000s (predictor variable)
. target: whether the crime rate is above the median crime rate (1) or not (0) (response variable)

### Summary Stats and Imputations

Below is the summary of the dataset and some inference of it. 

1. It seems there are no Null values in the predictor and response variables.
2. Each variables are in different scale.
3. Categorical variables are `chas` and `target`. 
4. There are a total of 466 observations and 13 predictor variables.


```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
head(df)
print(paste0('Observation count: ',count(df)))
summary(df)
```


### Plots and Correlation

Below is the detailed plot of all the variables.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
chart.Correlation(df,histogram=TRUE,pch=19)

```


1. Some of the variables like `zn`, `dis`,`black`,`age` are heavily skewed.
2. `tax` and `rad` Variables are heavily correlated. `nox` and `indus`, `nox` and `age`, `medv` and `rm` are moderatly positive correlated.
3. `dis` and `nox`, `dis` and `indus` are negativly correlated.


Below shown are the box plot of all the variables and barplot of target variables.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
boxplot(df,names = names(df))

barplot(table(df$target), main = 'Target Distribution', ylab='# of Crime Target',xlab='Target')
```

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}

data.frame(NA_count = sapply(df, function(x) sum(is.na(x)))) 

```



## Data Preparation

Data preparation is an important step of this analysis. As some of the variables are heavily skewed, we need to transform the variables.

### Data Transformations

As these variables `zn`, `dis`,`black`,`age` are skewed, we need to transform the variables.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
hist(df$zn)
hist(df$dis)
hist(df$black)
hist(df$age)

hist(log(df$dis),main = 'Log dis') 
```




```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}

df_transformed = df
  
summary(df_transformed)
df_transformed$dis = log(df$dis)


df_transformed$chas = factor(df$chas)
#df_transformed$target = factor(df$target)

# Need to be transformed 
hist(sqrt(df$black))
hist(sqrt(df$age))


#box_cox_transformation = function(df,var){
#  print(c(df[var]))
#boxcox_detail = boxcox(c(df[var]) ~ .,data = df, lambda= seq(-0.25,.25,length=10))
#lambda = boxcox_detail$x[which.max(boxcox_detail$y)]

#return((df[var] ^ lambda - 1)/lambda)
#}


#box_cox_transformation(df,'dis')


#log(df$black)


#boxcox(black ~ .,data = df, lambda= seq(-0.25,.25,length=10))
#boxcox(age ~ .,data = df, lambda= seq(-0.25,.25,length=10))

#qqnorm((df$dis ^ lambda - 1)/lambda) 


```

For other predictor variables, the transformations did not change the skweness in it. SO we will leave as it is. 


## Build Models

As a next step we will build different models and evaluate the metrics.


### Model 1 - Stepwise elimination - Logit model

As a first step we will build a `logit` model with backward elimination. In this model, we will remove the predictors which are not statistically significant.

```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}

# Function for printing all the analysis
analysis <- function(df,model){
  print(summary(model))
  print(paste0("BIC: ",BIC(model)))
  print(paste0("VIF: ",vif(model)))

  plot(model)
  plot(model,which = c(4))
  n = length(df$target)
  print(paste0("Naglekerke-pseudo-R2:",(1-exp((model$dev-model$null)/n))/(1-exp(-model$null/n))))
}

# Function for printing confusion matrix
confusion_analysis <- function(df,model){
  # Threshold value is 0.5, positive class is 1
  
  predicted = if_else(predict(model,df,type='response')>=0.5, 1,0)
  confusionMatrix(data = predicted,
                reference = df$target,
                positive = "1")
}

# Function for calculating evaluation metrics
summary_analysis <- function(df,model){
  print(summary(model))
  print(paste0("BIC: ",BIC(model)))
  print(paste0("VIF: ",vif(model)))

  n = length(df$target)
  print(paste0("Naglekerke-pseudo-R2:",(1-exp((model$dev-model$null)/n))/(1-exp(-model$null/n))))
  print("Confusion Matrix:")
  confusion_analysis(df,model)
  
}

model_11_base = glm(target ~ ., df_transformed, family=binomial(link = 'logit'))


``` 

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
analysis(df_transformed,model_11_base)

summary_analysis(df_transformed,model_11_base)
```

There are some outliers in the dataset. However, those are not influential points. So we will not remove any data points for now.

But there are some variables which are not statically significant. We will remove those variables one by one and try again.



```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
#Indus is highly correlated with other variables and not statiscially significant. So we will remove that

model_12_base_removed = update(model_11_base,.~.-indus)

#summary_analysis(df_transformed, model_12_base_removed)

# Removing Lstat
model_13_base_removed = update(model_12_base_removed,.~.-lstat)

#summary_analysis(df_transformed, model_13_base_removed)

# Removing rm
model_14_base_removed = update(model_13_base_removed,.~.-rm)

# summary_analysis(df_transformed, model_14_base_removed)

# Converges after removing the above predictor
model_15_base_removed = update(model_14_base_removed,.~.-chas )


```

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}

summary_analysis(df_transformed, model_15_base_removed)

```


It seems the best model which we can get is the above model with AIC score of ~`206.9`. But still it seems VIF is large for the predictor variables and `Naglekerke-pseudo-R2` is around `0.83`.


#### Individual variable analysis

Analyzing individual predictor and the target response will provide the strength of the predictor. Below function will calculate the probablities of individual predictors and then plot it.


```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
variable_analysis = function(df,variable){


temp_mdl = glm(target ~ variable, df, family=binomial(link = 'logit'))


xweight <- seq(range(variable)[1],range(variable)[2],length.out = length(variable))

yweight = predict(temp_mdl,new_data=list(xweight),type = 'response')

plot(xweight, df$target, pch = 16)

lines(xweight,sort(yweight),lwd=2)

}


variable_analysis(df_transformed,df_transformed$rm)
variable_analysis(df_transformed,df_transformed$dis)
variable_analysis(df_transformed,df_transformed$black)
variable_analysis(df_transformed,df_transformed$rad)
variable_analysis(df_transformed,df_transformed$tax)
variable_analysis(df_transformed,df_transformed$black)
variable_analysis(df_transformed,df_transformed$lstat)
```

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
# ZN
variable_analysis(df_transformed,df_transformed$zn)
# Indus
variable_analysis(df_transformed,df_transformed$indus)
#Nox
variable_analysis(df_transformed,df_transformed$nox)
#Age
variable_analysis(df_transformed,df_transformed$age)
```





### Model 2 - Stepwise elimination:Probit model

In this model, we are going to use `probit` as our link function using `glm` method. We will run the evaluation metrics on the model. Also remove the predictors which are not statistically significant.

```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
model_21_base = glm(target ~ ., df_transformed, family=binomial(link = 'probit'))

model_22_base_removed = update(model_21_base,. ~ .-indus-lstat-zn-chas)
```


```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
summary_analysis(df_transformed,update(model_21_base,. ~ .-indus-lstat-zn-chas))

```
After removing the statistically insignificant predictors, we can see that the AIC, BIC, and classfication is bad compared to `logit` model.



### Model 3 - Automatic Variable selection 

Lets try automatic variables selection using step method. It uses `AIC` to select the best parameters.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}

step (model_11_base, trace=F)

```

Using automatic selection methods, the best AIC we can get is ~205.9 which is better than manual stepwise selection. 

Now lets try to develop the model using AIC and BIC metrics using `bestglm` package.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
# Best model using AIC
bestglm(df_transformed,IC='AIC')

# Best model using BIC
bestglm(df_transformed,IC='BIC')

```
`bestglm` package converts the target variable as an regression variable and then performs the predition. This might not be the best approach to create a binary logistic regression.


### Model 4 - Bayesian Logistic Regression


In this model, we will run Bayesian type logistic regression. Bayesian model calculates the prior and posterior probability using Markov Chain Monte Carlo(MCMC) method.

`rstanarm` package provides functions to run Bayesian type models. 

```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}

#Reference: https://www.kaggle.com/avehtari/bayesian-logistic-regression-with-rstanarm

df_transformed$target=factor(df_transformed$target)

t_prior =student_t(df=14, location = 0, scale = 2.5)

post1 <- stan_glm(target ~ . ,data =df_transformed,family=binomial(link='logit'),
                  prior = t_prior, prior_intercept = t_prior, seed =1)

model_41_bayesian = post1 

```

Below is the summary of the bayesian model. It runs for various iterations and the provides coefficients. 

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
summary(post1)
```



```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}

pplot<-plot(post1, "areas", prob = 0.95, prob_outer = 1)
pplot+ geom_vline(xintercept = 0)
```

Coefficients of predictor variables and its confidence intervals.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
round(coef(post1), 2)
round(posterior_interval(post1, prob = 0.9), 2)
```


```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
# Predicted probabilities
linpred <- posterior_linpred(post1)
preds <- posterior_linpred(post1, transform=TRUE)
pred <- colMeans(preds)
pr <- as.integer(pred >= 0.5)


```

Evaluation metrics of Bayesian models.

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
confusionMatrix(data = pr,
                reference = df$target,
                positive = "1")
```




### Model 5 - Scaled Basyesian/logit approach

In this model, we will evaluate if the scaling makes any difference in our model. We will scale the predictor variables and comeup with a solution.

#### Logit approach

In the previous model, we have not scaled the data. In this model, we will to  scale the predictors and remove the outliers.


```{r include=FALSE, echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE}

names(df)

df_scale <- data.frame(target = df_transformed[,c('target')], scale(df_transformed[,c("zn","indus","nox","rm","age","dis","rad","tax","ptratio","black"  , "lstat","medv" )]),chas = factor(df_transformed[,c('chas')]))



model_51_scale <- glm(target ~ .,data = df_scale,family = binomial(link='logit'))



model_52_scale_removed = update(model_51_scale,.~.-indus-lstat-chas-rm)

```

```{r include=TRUE, echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
summary_analysis(df_scale, model_52_scale_removed)

```



It seems scaling the predictor variables did improve the model but it is very little.



#### Bayesian approach

```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
df_transformed$target=factor(df_scale$target)

t_prior =student_t(df=14, location = 0, scale = 2.5)

model_61_bayseian_scaled <- stan_glm(target ~ . ,data =df_scale,family=binomial(link='logit'),
                  prior = t_prior, prior_intercept = t_prior, seed =1)

linpred <- posterior_linpred(model_61_bayseian_scaled)
preds <- posterior_linpred(model_61_bayseian_scaled, transform=TRUE)
pred <- colMeans(preds)
pr <- as.integer(pred >= 0.5)


```


```{r include=TRUE, echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
confusionMatrix(data = pr,
                reference = df_scale$target,
                positive = "1")
```




Seems scaling has no effect on Bayesian logistic regression. So we will use it as a final model and evaluate the test dataset.

## Select Models

We have evaluated all the models using our training data. Now we need to select the best model for further predications. We will select three different models from the above analysis. `logit`, `probit` and `Bayesian model`.  

### Predictions

```{r include=FALSE, echo=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
df_test <- read.csv('./data/crime-evaluation-data.csv')

df_test$dis = log(df_test$dis)
df_test$chas = factor(df_test$chas)
```


```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
pr_model1 = if_else(predict(model_15_base_removed,newdata = df_test,type='response')>=0.5, 1,0)
pr_model2 = if_else(predict(model_22_base_removed,newdata =df_test,type='response')>=0.5, 1,0)

pr_model4 = c(posterior_predict(model_41_bayesian,df_test)[4000,])


```

Below is the predictions of all the three models. 

```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}
data.frame(logit_model = pr_model1,probit_model = pr_model2,bayes=pr_model4)
```


| Metric    | Logit  | Probit | Bayes | Automatic  
| --------- | ------------- | ----------- | ------- | -------------  
| AIC       |  206.44       |  212.34       | -   |  205.5     
| BIC       | 247.88       | 270.36      | -  | -    
| Naglekerke-pseudo-R2  | 0.835       | 0.835      | -  | -    
| Accuracy   | 0.927         | 0.920       | 0.922   | -   


Based on the above metrics, automatic selection is performing best. After than logit model is performing well in this dataset. Bayesian method works well, but we need to calcuate other metrics for proper validation. As automatic variable selection cannot be explained, we will choose logit model for this dataset.

```{r include=FALSE, echo=FALSE,   warning=FALSE, message=FALSE}
rocCurve <- roc(response = df_transformed$target,
                predictor = predict(model_15_base_removed,newdata = df_transformed,type='response'),
                  levels = c(1,0))
```



```{r include=TRUE, echo=FALSE,   warning=FALSE, message=FALSE}


print('ROC Curve:')
auc(rocCurve)


plot(y = rocCurve$sensitivities, ylab = "Sensitivity", x = 1 - rocCurve$specificities, xlab = "1 - Specificity",
main = "ROC Curve", col = "red")
```











