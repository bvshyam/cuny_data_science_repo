{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits Classification using Keras CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset:\n",
    "\n",
    "The MNIST database of handwritten digits, available from [this page](http://yann.lecun.com/exdb/mnist/), has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "In this project we will build a Convolutional Neural Network(CNN) to find out the handwritten digits. These neural networks will be build using different layers. \n",
    "\n",
    "We will use Keras high-level library to perform this prediction. Tensorflow is used in backend for this network. Neural network can be build using different API's in Keras. Below are two different methods. \n",
    "\n",
    "1. Keras Sequential API\n",
    "2. Keras Functional API\n",
    "\n",
    "Once we build this model, we will execute the either option to run in GPU's to make faster execution and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D, AvgPool2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "from keras.layers import Flatten, Activation\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout\n",
    "import keras.backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequential_model():\n",
    "    \n",
    "    \"\"\"In Option 1, we are going to create a model in sequence of different steps. Here we add series of neural network layer steps to create a fully connected network and \n",
    "    then perfrom prediction using the final layer.\"\"\"\n",
    "    \n",
    "    # Create a sequential Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(28,28,1),strides=(1,1),padding='same',\n",
    "                 kernel_regularizer='l2',kernel_initializer='normal'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(units=128,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    print('Sequential Model Summary: {}\\n'.format(model.summary()))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def functional_model():\n",
    "    \n",
    "    \"\"\"In Option 2, we will use the sophisticated functions API provided by Keras. My using this method, we can provide multiple inputs in various different forms. \n",
    "    It also has lot of flexibility compared to the Sequential API.\"\"\"\n",
    "    #Input shape of the data\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    \n",
    "    #Adding multiple layers as we performed in Sequential API\n",
    "\n",
    "    x = Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),kernel_regularizer='l2', \\\n",
    "               kernel_initializer='normal')(inputs)\n",
    "    \n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x= Dropout(0.1)(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),kernel_regularizer='l2', \\\n",
    "               kernel_initializer='normal')(x)\n",
    "    \n",
    "    x = MaxPool2D(pool_size=(2,2))(x)\n",
    "    \n",
    "    x= Dropout(0.1)(x)\n",
    "    x= BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(128,activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    predictions = Dense(10,activation='softmax')(x)\n",
    "    \n",
    "    #Create a model and predict\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    print('Functional Model Summary: {}\\n'.format(model.summary()))\n",
    "\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_call(X_train, X_test, y_train_cat, y_test_cat):\n",
    "    \"\"\"Another complexity we are going to add to this model is to perform image generation. We are going to add new images by recaling, shifting width, height, rotation, shear, zoom and horizontal flip, etc. \n",
    "    By performing this operation, we can generate new images and by confident about our model and predictions.\"\"\"\n",
    "    \n",
    "    train_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                           width_shift_range=0.1,\n",
    "                           height_shift_range=0.1,\n",
    "                           rotation_range = 10,\n",
    "                           shear_range = 0.2,\n",
    "                           zoom_range = 0.2,\n",
    "                           horizontal_flip = True)\n",
    "    test_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    tra = train_gen.flow(X_train,y_train_cat)\n",
    "    \n",
    "    #After adding new images, lets see a sample image and its output. By seeing these outputs, some images have been got totally transformed. \n",
    "    #Lets see how the model behaves on these totally transformed images.\n",
    "    #for t in tra:\n",
    "        #print(t[0][0].reshape(28,28))\n",
    "    #    plt.imshow(t[0][0].reshape(28,28),cmap='gray')\n",
    "    #    print(\"Actual number is {}\\n\".format(np.argmax(t[1][0])))\n",
    "    #    break\n",
    "            \n",
    "    return train_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consolidated_model( X_train, X_test, y_train_cat, y_test_cat,image_generate=False,model_type='Sequential'):\n",
    "    \n",
    "    \"\"\"Below is the series of steps added to the model\n",
    "    1. Add a convolutional 2D layer with the kernal size of 3x3 and strides of 1x1.\n",
    "    2. We can add l2 regularizer and initiate the kernel weigths to normal weights.\n",
    "    3. Add MaxPool2D layer, which reduces the image size with 2x2 kernal size. It will try to detect the corners and important features.\n",
    "    4. Randomly dropout the 10% of neurons. This will prevent the model to be dependent on some certain neurons.\n",
    "    5. Add BatchNormalization will transorm the previous layers output mean close to 0 and the SD close to 1.\n",
    "    6. Adding all the previous steps (convolution2D, MaxPool2D, Dropout, BatchNormalization) to the model.\n",
    "    7. Adding the activation function Relu.\n",
    "    8. Flatten the complete array to create a Fully connectected neural network.\n",
    "    9. Add a output layer with 128 neurons with relu activation.\n",
    "    10. Finally add a softmax layer with 10 output neurons to predict the output.\n",
    "    11. Complie the model with RMSPROP optimzer and categorical cross entropy loss with accuracy as the metric.\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_type =='Sequential':\n",
    "        model = sequential_model()\n",
    "        \n",
    "    elif model_type=='Functional':\n",
    "        model = functional_model()\n",
    "    \n",
    "\n",
    "    # Creating some call back functions\n",
    "    earlystopping = EarlyStopping(monitor='val_loss',min_delta=0, patience=5, mode ='auto')\n",
    "    #Tensorboard logs\n",
    "    tensorboard = TensorBoard(log_dir='./logs')\n",
    "    \n",
    "    \n",
    "    if image_generate ==True:\n",
    "        train_gen, test_gen = generate_call(X_train, X_test, y_train_cat, y_test_cat)\n",
    "        \n",
    "        #Saving best model\n",
    "        modelcheckpoint = ModelCheckpoint('./model/save_model_fit_generator.hdf5', monitor ='val_loss',save_best_only=True,)\n",
    "\n",
    "        #Fit method provides higher accuracy but we did not generate new images which is of different sizes, zoom, etc. Below fit method will will use the newly generated images and then perform fit method.\n",
    "        #Image generator creates an generator object, so we have to use flow method to generate new images. This method is extremely slow, so we are performing only two epochs.\n",
    "\n",
    "        model.fit_generator(train_gen.flow(X_train,y_train_cat),epochs=10,steps_per_epoch=len(X_train)\n",
    "                   ,callbacks =[earlystopping,modelcheckpoint,tensorboard])\n",
    "        \n",
    "        \n",
    "        #print(\"Evaluate model accuracy with new images: {}\".format(model.evaluate(X_test,y_test_cat)))\n",
    "\n",
    "        \n",
    "    elif image_generate ==False:\n",
    "        \n",
    "        modelcheckpoint = ModelCheckpoint('./model/save_model_fit.hdf5', monitor ='val_loss',save_best_only=True)\n",
    "    \n",
    "        #Fitting the model with a batch size of 128 and 10 epochs without any new image generator. This provides higher accuracy\n",
    "        \n",
    "        model.fit(X_train,y_train_cat,batch_size=128,validation_split=0.1,\n",
    "                  epochs=100,callbacks =[earlystopping,modelcheckpoint,tensorboard])\n",
    "        \n",
    "        \n",
    "        print(\"Evaluate model accuracy without new images: {}\".format(model.evaluate(X_test,y_test_cat)[1] *100))\n",
    "    \n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating the shape of X_train: (60000, 28, 28)\n",
      "\n",
      "Validating the shape of X_test:(10000, 28, 28)\n",
      "\n",
      "\n",
      "***Sequentional without new generated images***\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Functional Model Summary: None\n",
      "Model Prediction: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x161f53c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    #MNIST dataset is conveniently available as part of Keras.datasets library. We will import the dataset and split it in Train test split in random order.\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data('mnist.npz')\n",
    "    \n",
    "    print(\"Validating the shape of X_train: {}\\n\".format(X_train.shape))\n",
    "    print(\"Validating the shape of X_test:{}\\n\".format(X_test.shape))\n",
    "    \n",
    "    #Image of random train object\n",
    "    plt.imshow(X_train[9999],cmap='gray')\n",
    "    \n",
    "    #The image pixel range is from 0 to 255. We need to convert it to float and divide by 255. By performing this we will reduce the computations carred by neural network.\n",
    "    \n",
    "    # Convert integer to float and divide by 255\n",
    "    X_train = X_train.astype('float32')/255\n",
    "    X_test = X_test.astype('float32')/255\n",
    "    \n",
    "    \n",
    "    #To perform convolution on the image, we need to convert the image into 28x28 pixels. Also the input needs to be a rank 4 tensor. First input is the number of rows, here -1 means it will fetch at run time. Other two dimentions are image pixels. Final dimension mentions the image color. \n",
    "    #In our case, it is gray scale so it is mentioned as 1.\n",
    "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    #Converting to y to categorical variable\n",
    "    y_train_cat = to_categorical(y_train)\n",
    "    y_test_cat = to_categorical(y_test)\n",
    "    \n",
    "    #Sequential call\n",
    "    \n",
    "    print(\"\\n***Sequentional without new generated images***\\n\")\n",
    "    model = consolidated_model(X_train, X_test, y_train_cat, y_test_cat,image_generate=False,model_type='Functional')\n",
    "    \n",
    "    print(\"\\n***Sequentional with new images***\\n\")\n",
    "    \n",
    "    model = consolidated_model(X_train, X_test, y_train_cat, y_test_cat,image_generate=True,model_type='Sequential')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
