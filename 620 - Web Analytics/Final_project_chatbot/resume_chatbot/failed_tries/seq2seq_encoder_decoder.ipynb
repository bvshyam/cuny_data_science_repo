{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_as_words(data_path = 'fra-eng/final_qa_data.csv', num_samples = 269):\n",
    "    tokenizer_en = Tokenizer(num_words=None, filters='\"#$%&()*+,/:;=?@[\\\\]^_`{|}~\\t\\n',\n",
    "               lower=True,\n",
    "               split=\" \",\n",
    "               char_level=False)\n",
    "    tokenizer_fr = Tokenizer(num_words=None, filters='',\n",
    "                   lower=True,\n",
    "                   split=\" \",\n",
    "                   char_level=False)\n",
    "    \n",
    "    english_sentences = []\n",
    "    french_sentences = []\n",
    "    \n",
    "    lines = open(data_path,encoding='utf8').read().split('\\n')\n",
    "    for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "        line_split = line.split(',')\n",
    "        english_sentence = [line_split[0].replace('.',' . ').replace('!',' ! ').replace('?',' ? ').replace(',',' , ').replace(\"'\",\" '\")]\n",
    "        english_sentences = english_sentences + english_sentence\n",
    "        french_sentence = ['<START> ' \n",
    "                            + line_split[1].replace('.',' . ').replace('\\u202f',' ').replace('!',' ! ').replace('?',' ? ').replace(',',' , ').replace(\"'\",\" '\")\n",
    "                            + '<STOP>']\n",
    "        french_sentences = french_sentences + french_sentence\n",
    "\n",
    "    tokenizer_en.fit_on_texts(english_sentences)\n",
    "    tokenizer_fr.fit_on_texts(french_sentences)\n",
    "    \n",
    "    idx2Word_en={0:'<PAD>'}\n",
    "    for key, value in tokenizer_en.word_index.items():\n",
    "        idx2Word_en[value] = key\n",
    "    \n",
    "    idx2Word_fr={0:'<PAD>'}\n",
    "    for key, value in tokenizer_fr.word_index.items():\n",
    "        idx2Word_fr[value] = key\n",
    "    \n",
    "    \n",
    "    encoder_input_data = tokenizer_en.texts_to_sequences(english_sentences)\n",
    "    encoder_input_data = pad_sequences(encoder_input_data, maxlen=None, dtype='int32', padding='post', truncating='post', value=0)\n",
    "    french_tokenized = tokenizer_fr.texts_to_sequences(french_sentences)\n",
    "    french_tokenized = pad_sequences(french_tokenized, maxlen=None, dtype='int32', padding='post', truncating='post', value=0)\n",
    "    decoder_input_data = french_tokenized[:,:-1]\n",
    "    decoder_target_data = french_tokenized[:,1:]\n",
    "    word2Idx_en = tokenizer_en.word_index\n",
    "    word2Idx_fr = tokenizer_fr.word_index\n",
    "    num_encoder_tokens = len(idx2Word_en)\n",
    "    num_decoder_tokens = len(idx2Word_fr)\n",
    "    decoder_target_data_cat = to_categorical(decoder_target_data.reshape(1,-1)[0]).reshape(len(decoder_target_data), decoder_target_data.shape[1], num_decoder_tokens)\n",
    "    \n",
    "    return english_sentences, french_sentences, \\\n",
    "            encoder_input_data, \\\n",
    "            decoder_input_data, \\\n",
    "            decoder_target_data_cat, \\\n",
    "            num_encoder_tokens, num_decoder_tokens, \\\n",
    "            idx2Word_en, idx2Word_fr, \\\n",
    "            word2Idx_en, word2Idx_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_embedding_model_inference(num_encoder_tokens, num_decoder_tokens, latent_dim = 256):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
    "    x, state_h, state_c = LSTM(latent_dim,\n",
    "                            return_state=True)(x)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_embedd = Embedding(num_decoder_tokens, latent_dim)\n",
    "    x = decoder_embedd(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    x,_,_ = decoder_lstm(x, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,), name=\"State_input_h\")\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,), name=\"State_input_c\")\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    x = decoder_embedd(decoder_inputs)\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(x, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_embedding_model(num_encoder_tokens, num_decoder_tokens, latent_dim = 256):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    x = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
    "    x, state_h, state_c = LSTM(latent_dim,\n",
    "                            return_state=True)(x)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    decoder_embedd = Embedding(num_decoder_tokens, latent_dim)\n",
    "    x = decoder_embedd(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    x,_,_ = decoder_lstm(x, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(x)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, None, 128)    36864       input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, None, 128)    33664       input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  [(None, 128), (None, 131584      embedding_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  [(None, None, 128),  131584      embedding_18[0][0]               \n",
      "                                                                 lstm_17[0][1]                    \n",
      "                                                                 lstm_17[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 263)    33927       lstm_18[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 367,623\n",
      "Trainable params: 367,623\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 209 samples, validate on 53 samples\n",
      "Epoch 1/10\n",
      "128/209 [=================>............] - ETA: 3s - loss: 5.5771Epoch 00001: val_loss improved from inf to 5.30717, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py:2344: UserWarning: Layer lstm_18 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_17/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_17/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 8s 39ms/step - loss: 5.5494 - val_loss: 5.3072\n",
      "Epoch 2/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 5.4038Epoch 00002: val_loss improved from 5.30717 to 2.85435, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 5.2748 - val_loss: 2.8544\n",
      "Epoch 3/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 3.6795Epoch 00003: val_loss improved from 2.85435 to 1.68006, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 3.3844 - val_loss: 1.6801\n",
      "Epoch 4/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.9799Epoch 00004: val_loss did not improve\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.9714 - val_loss: 1.6937\n",
      "Epoch 5/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.9226Epoch 00005: val_loss improved from 1.68006 to 1.65369, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.8891 - val_loss: 1.6537\n",
      "Epoch 6/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.8041Epoch 00006: val_loss improved from 1.65369 to 1.64090, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.8256 - val_loss: 1.6409\n",
      "Epoch 7/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.7394Epoch 00007: val_loss did not improve\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.7583 - val_loss: 1.6669\n",
      "Epoch 8/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.7265Epoch 00008: val_loss did not improve\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.7646 - val_loss: 2.0452\n",
      "Epoch 9/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.9152Epoch 00009: val_loss improved from 1.64090 to 1.57489, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 6ms/step - loss: 2.9202 - val_loss: 1.5749\n",
      "Epoch 10/10\n",
      "128/209 [=================>............] - ETA: 0s - loss: 2.6708Epoch 00010: val_loss improved from 1.57489 to 1.53042, saving model to seq2seq_enc_dec_model_128_269_best.hdf5\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 2.6626 - val_loss: 1.5304\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    num_samples = 269\n",
    "    english_sentences, french_sentences, \\\n",
    "    encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "    num_encoder_tokens, num_decoder_tokens, \\\n",
    "    idx2Word_en, idx2Word_fr, \\\n",
    "    word2Idx_en, word2Idx_fr = get_data_as_words(num_samples = num_samples)\n",
    "    latent_dim = 128\n",
    "    model = get_words_embedding_model(num_encoder_tokens, num_decoder_tokens, latent_dim = latent_dim)\n",
    "    model.summary()\n",
    "    # Compile & run training\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "    # Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "    # rather than sequences of integers like `decoder_input_data`!\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "    file_name = 'seq2seq_enc_dec_model_'+str(latent_dim)+'_'+str(num_samples)\n",
    "    checkpoint = ModelCheckpoint(file_name+'_best.hdf5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=0.2,\n",
    "              callbacks = callbacks_list)\n",
    "\n",
    "    file_name = 'seq2seq_enc_dec_model_'+str(latent_dim)+'_'+str(num_samples)\n",
    "    #model.save_weights(file_name+'.hdf5')\n",
    "    np.save(file_name, model.history.history)\n",
    "\n",
    "if __name__ == \"__main__\": main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 26, 263)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, None, 128)    36864       input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, None, 128)    33664       input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  [(None, 128), (None, 131584      embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  [(None, None, 128),  131584      embedding_20[0][0]               \n",
      "                                                                 lstm_19[0][1]                    \n",
      "                                                                 lstm_19[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 263)    33927       lstm_20[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 367,623\n",
      "Trainable params: 367,623\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_19 (Embedding)     (None, None, 128)         36864     \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 168,448\n",
      "Trainable params: 168,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, None, 128)    33664       input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "State_input_h (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "State_input_c (InputLayer)      (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  [(None, None, 128),  131584      embedding_20[1][0]               \n",
      "                                                                 State_input_h[0][0]              \n",
      "                                                                 State_input_c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, None, 263)    33927       lstm_20[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 199,175\n",
      "Trainable params: 199,175\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_samples = 269 #28500\n",
    "latent_dim = 128 #256\n",
    "english_sentences, french_sentences, \\\n",
    "encoder_input_data, decoder_input_data, decoder_target_data, \\\n",
    "num_encoder_tokens, num_decoder_tokens, \\\n",
    "idx2Word_en, idx2Word_fr, \\\n",
    "word2Idx_en, word2Idx_fr = get_data_as_words(num_samples = num_samples)\n",
    "\n",
    "model, encoder_model, decoder_model = get_words_embedding_model_inference(num_encoder_tokens, num_decoder_tokens, latent_dim = latent_dim)\n",
    "model.summary()\n",
    "encoder_model.summary()\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_decoder_seq_length = decoder_target_data.shape[1]\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.array([word2Idx_fr['<start>']])\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        \n",
    "        sampled_char = idx2Word_fr[sampled_token_index]\n",
    "        decoded_sentence = decoded_sentence + sampled_char + ' '\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '<stop>' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.array([sampled_token_index])\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating references indexes\n",
      "Creating references and translating\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([2])]...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-7cc58a6c2c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Created!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mreferences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ref_and_cand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m262\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-82-7cc58a6c2c33>\u001b[0m in \u001b[0;36mget_ref_and_cand\u001b[1;34m(english_sentences, french_sentences, number_translations)\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mreference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrench_sentences_np\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mref_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mreferences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mcandidates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Created!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-82-7cc58a6c2c33>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sec_n)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0minput_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msec_n\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msec_n\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# print([idx2Word_en[word] for word in input_seq[0]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecoded_sentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<stop>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[0mfrench_sentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msec_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<START>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<STOP>'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-81-eecf3da5b7bb>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Sample a token\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1728\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1729\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1730\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     87\u001b[0m                                  \u001b[1;34m'the following list of '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                                  \u001b[1;34m' arrays: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                                  '...')\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 3 array(s), but instead got the following list of 1 arrays: [array([2])]..."
     ]
    }
   ],
   "source": [
    "### 0, 10, 19, 1000, 1001\n",
    "def translate(sec_n = 0):\n",
    "    input_seq = encoder_input_data[sec_n:sec_n+1]\n",
    "    # print([idx2Word_en[word] for word in input_seq[0]])\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    return decoded_sentence.replace('<stop>','').split(), \\\n",
    "        french_sentences[sec_n].replace('<START>','').replace('<STOP>','').lower().split()\n",
    "\n",
    "def get_ref_and_cand(english_sentences, french_sentences, number_translations):\n",
    "    english_sentences_np = np.array(english_sentences)\n",
    "    french_sentences_as_list = [sen.replace('<START>','').replace('<STOP>','').lower().split() for sen in french_sentences]\n",
    "    french_sentences_np = np.array(french_sentences_as_list)\n",
    "    print('Creating references indexes')\n",
    "    reference_indexes = []\n",
    "    for eng_np in english_sentences_np:\n",
    "        indxs = np.array(np.where(english_sentences_np==eng_np)[0])\n",
    "        if (len(reference_indexes)>0):\n",
    "            if len(reference_indexes[-1])!=len(indxs):\n",
    "                result = 0\n",
    "            else:\n",
    "                result = (reference_indexes[-1] == indxs).prod()  \n",
    "            if (result==0):\n",
    "                reference_indexes.append(indxs)\n",
    "        else:\n",
    "            reference_indexes.append(indxs)\n",
    "    print('Creating references and translating')\n",
    "    references = []\n",
    "    candidates = []\n",
    "    count = 0\n",
    "    for ref_idx  in reference_indexes[:number_translations]:\n",
    "        reference = list(french_sentences_np[ref_idx])\n",
    "        references.append(reference)\n",
    "        candidates.append(translate(count)[0])\n",
    "        count = count+len(reference)\n",
    "    print('Created!')\n",
    "    return references, candidates\n",
    "references, candidates = get_ref_and_cand(english_sentences, french_sentences, 262)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi'],\n",
       " ['ils', 'donne-les-moi']]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14241131333821394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "score = corpus_bleu(references, candidates)\n",
    "print(score)\n",
    "\n",
    "history = np.load('seq2seq_enc_dec_model_128_1000.npy')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm0+vsU2kGdcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12510be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.reshape(1)[0]['val_loss'])\n",
    "plt.plot(history.reshape(1)[0]['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
